# -*- coding: utf-8 -*-
"""llama_genetic_algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FXJ7DJJJFcEQ9NyzNMtkX-NXXT1ngo2U

# Install Required Packages and Install LLama Model
Author:Sridhar Sharma
"""

!pip install python-multipart
!pip install uvicorn
!pip install fastapi
!pip install kaleido
!pip install cohere
!pip install openai
!pip install tiktoken

# GPU llama-cpp-python
!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78 numpy==1.23.4 --force-reinstall --upgrade --no-cache-dir --verbose
!pip install llama-cpp-python==0.1.78
!pip install numpy==1.23.4

import numpy as np
import re

!pip install huggingface_hub

from huggingface_hub import hf_hub_download

from llama_cpp import Llama

"""### Pick The Model"""

model_name_or_path = "TheBloke/Llama-2-13B-chat-GGML"
model_basename = "llama-2-13b-chat.ggmlv3.q5_1.bin" # the model is in bin format

"""# Download the Model"""

from huggingface_hub import hf_hub_download

model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)

"""# Setup Machine Parameters"""

# GPU
lcpp_llm = None
lcpp_llm = Llama(
    model_path=model_path,
    n_threads=2, # CPU cores
    n_batch=512, # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.
    n_gpu_layers=32 # Change this value based on your model and your GPU VRAM pool.
    )

!pip install datasets

"""## Import Dataset (GSM8K)"""

from datasets import load_dataset

dataset = load_dataset("gsm8k", 'main')

train_data = dataset["train"]
test_data = dataset["test"]

print('Length of Training Dataset is ',len(train_data))
print('Length of Test Dataset is ',len(test_data))

"""## Utility Functions"""

def last_number(s):
    numbers = re.findall(r'\d+', s)
    return int(numbers[-1]) if numbers else None

def bring_examples_gsm8k(dataset, max_num_examples):

    examples = []

    indexes = np.random.randint(len(dataset['train']), size=max_num_examples)

    for index in indexes:

        examples.append('Q: ' + dataset['train'][int(index)]['question'] + '\nA: ' + dataset['train'][int(index)]['answer'])

    return examples


def bring_problems_to_solve_gsm8k(dataset, max_num_problems):

    problems, answers = [], []

    indexes = np.random.randint(len(dataset['train']), size=max_num_problems)

    for index in indexes:

        problems.append('Q: ' + dataset['train'][int(index)]['question'] + '\nA: ')
        answers.append(dataset['train'][int(index)]['answer'])

    return problems, answers

def create_prompts(prompt_template,problems,max_num_problems):
    problem_with_prompt=[]
    for i in range(len(problems)):
        prompt=prompt_template+problems[i]+f''' Assistant:
         '''
        problem_with_prompt.append(prompt)
    return problem_with_prompt



def evaluate_problems(problem_prompts,answers):
    evaluations = np.zeros(len(answers))

    model_ans = ['']*len(answers)

    for i in range(len(problem_prompts)):
        prompt = problem_prompts[i]

        print(prompt)
        response =lcpp_llm(prompt=prompt, max_tokens=1024, temperature=0.5, top_p=0.95,
                  repeat_penalty=1.2, top_k=150,
                  echo=True)
        print(response['choices'][0]['text'])
        print('Actual Answer is ', last_number(answers[i]))
        print('Generated Answer is ',last_number(response['choices'][0]['text']))
        if last_number(answers[i]) == last_number(response['choices'][0]['text']):
            evaluations[i] = 1
            model_ans[i]= response['choices'][0]['text']

    return evaluations



"""# Use LLAMA to evaluate GSM8K Dataset"""

[problems,answers]=bring_problems_to_solve_gsm8k(dataset,10)
problems

prompt_template=f'''

SYSTEM: You are a helpful assistant.
USER:
'''
problems_prompt=create_prompts(prompt_template,problems,10)
import time

# Start time
start_time = time.time()
evaluations=evaluate_problems(problems_prompt,answers)
# End time
end_time = time.time()

# Calculate elapsed time
elapsed_time = end_time - start_time
accuracy=np.sum(evaluations)/len(evaluations)*100
print('Accuarcy of one member of population is ',accuracy)
print('Elapsed Time for evaluating one member of population is ',elapsed_time)

print(elapsed_time)

print(np.sum(evaluations))

prompt_template=f'''

SYSTEM: You are a helpful assistant.
USER:
'''
problems_prompt=create_prompts(prompt_template,problems,10)
print(problems_prompt[0])