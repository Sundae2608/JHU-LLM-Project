{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb757ba1-c02d-4e55-83b1-a3dae40daa42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from constants import *\n",
    "from evaluator import *\n",
    "from model import *\n",
    "from mutator import *\n",
    "from prompt import *\n",
    "from task import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39226e28-1c1b-42c5-b189-9229336caf75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_last_numeric_value(input_string):\n",
    "    # Regular expression pattern to extract all numeric values with periods and ignoring commas\n",
    "    pattern = r'[\\d,.]+'\n",
    "\n",
    "    # Find all matches using re.finditer()\n",
    "    matches = re.finditer(pattern, input_string)\n",
    "\n",
    "    # Initialize a variable to store the last numeric value\n",
    "    last_numeric_value = None\n",
    "\n",
    "    # Iterate through the matches and update the last_numeric_value\n",
    "    for match in matches:\n",
    "        numeric_value = match.group()\n",
    "        # Remove commas if needed\n",
    "        numeric_value = numeric_value.replace(\",\", \"\")\n",
    "        last_numeric_value = numeric_value\n",
    "\n",
    "    return last_numeric_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dfc5475-2466-450f-993c-ef50ba0b99e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_func(orig, pred):\n",
    "    orig_value = extract_last_numeric_value(orig)\n",
    "    pred_value = extract_last_numeric_value(pred)\n",
    "    try:\n",
    "        return abs(float(orig_value) - float(pred_value)) < 1e-6\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a707869-52da-41e5-9004-e54b09d19a5e",
   "metadata": {},
   "source": [
    "# Step 1: Set up all the models that we want to quantify performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0abf7e77-2f67-44d3-82ef-a0d5dc4d78e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e66384fa27b4ac18b473835dc0042e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab76c49972d4437857522f5fb0483a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "model_mistral = Model(provider=\"quantized_llama\", model_name=\"TheBloke/Mistral-7B-OpenOrca-GGUF\", model_file=\"mistral-7b-openorca.Q4_K_M.gguf\", model_type=\"mistral\")\n",
    "model_llama_13 = Model(provider=\"fireworks\", model_name=\"accounts/fireworks/models/llama-v2-13b-chat\")\n",
    "model_llama_70 = Model(provider=\"fireworks\", model_name=\"accounts/fireworks/models/llama-v2-70b-chat\")\n",
    "model_open_ai = Model(provider=\"openai\", model_name=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e11f2a3-3268-4c28-9a7a-8d8c5a05d8d6",
   "metadata": {},
   "source": [
    "# Step 2: All base line evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17ac93ea-7211-4feb-979a-a7bb1bdf9eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_instruction = \"\"\n",
    "thinking_style = \"\"\n",
    "task = Task(load_dataset('gsm8k', 'main'),\n",
    "            'Solve the math word problem, giving your answer as an arabic numeral.',\n",
    "            evaluate_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05152113-f11b-47a5-b7e9-0707195adc53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e80af42-3a6d-4710-bc7f-585352ff92e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n"
     ]
    }
   ],
   "source": [
    "# Get the test indices, for consistency in evaluations\n",
    "NUM_EVALUATIONS = 100\n",
    "test_indices, test_samples = task.test_samples(NUM_EVALUATIONS)\n",
    "print(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1969246f-4f14-4eb0-b04a-d3847157a377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_indices = [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e035cf6a-77d5-4a49-bb73-f1461b1df014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(evaluation_model, folder_path, all_pop):\n",
    "    all_pop = [prompt.copy() for prompt in all_pop]\n",
    "    evaluator_params = EvaluatorParams(folder_path, print_text_completion=False, store_text_completion=True, print_evaluation_steps=10)\n",
    "    evaluator = Evaluator(evaluator_params)\n",
    "    scores = evaluator.evaluate(evaluation_model, task, all_pop, 100, test_indices)\n",
    "\n",
    "    # Print prompt and their score\n",
    "    prompt_scores = [(all_pop[i].get_accuracy(), all_pop[i]) for i in range(len(all_pop))]\n",
    "    prompt_scores = sorted(prompt_scores, key=lambda x: x[0], reverse=True)\n",
    "    print(\"Score  | Evals | Prompt\")\n",
    "    for _, prompt in prompt_scores:\n",
    "        print(f\"{prompt.get_accuracy() * 100:5.2f}% | {prompt.get_num_evals():5d} | {prompt}\")\n",
    "\n",
    "    # Store the generation data\n",
    "    prompt_genes = [prompt.gene() for prompt in all_pop]\n",
    "    prompt_evals = [prompt.get_num_evals() for prompt in all_pop]\n",
    "    prompt_accus = [prompt.get_accuracy() for prompt in all_pop]\n",
    "    data = {\n",
    "        \"Gene\": prompt_genes,\n",
    "        \"Evaluations\": prompt_evals,\n",
    "        \"Accuracy\": prompt_accus\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"{folder_path}/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e9a6c20-ea72-4a5c-945e-d94fa8f6a1c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (Solve the math word  -                      -                      - 0)\n",
      "Num evals: 10 - Accuracy: 10.00%\n",
      "Num evals: 20 - Accuracy: 25.00%\n",
      "Num evals: 30 - Accuracy: 20.00%\n",
      "Num evals: 40 - Accuracy: 20.00%\n",
      "Num evals: 50 - Accuracy: 20.00%\n",
      "Num evals: 60 - Accuracy: 20.00%\n",
      "Num evals: 70 - Accuracy: 20.00%\n",
      "Num evals: 80 - Accuracy: 21.25%\n",
      "Num evals: 90 - Accuracy: 21.11%\n",
      "Num evals: 100 - Accuracy: 23.00%\n",
      "Evaluating prompt 1: (Solve the math word  -                      -                      - 1)\n",
      "Num evals: 10 - Accuracy: 30.00%\n",
      "Num evals: 20 - Accuracy: 40.00%\n",
      "Num evals: 30 - Accuracy: 40.00%\n",
      "Num evals: 40 - Accuracy: 37.50%\n",
      "Num evals: 50 - Accuracy: 36.00%\n",
      "Num evals: 60 - Accuracy: 38.33%\n",
      "Num evals: 70 - Accuracy: 41.43%\n",
      "Num evals: 80 - Accuracy: 40.00%\n",
      "Num evals: 90 - Accuracy: 38.89%\n",
      "Num evals: 100 - Accuracy: 36.00%\n",
      "Evaluating prompt 2: (Solve the math word  -                      -                      - 3)\n",
      "Num evals: 10 - Accuracy: 70.00%\n",
      "Num evals: 20 - Accuracy: 55.00%\n",
      "Num evals: 30 - Accuracy: 56.67%\n",
      "Num evals: 40 - Accuracy: 47.50%\n",
      "Num evals: 50 - Accuracy: 44.00%\n",
      "Num evals: 60 - Accuracy: 51.67%\n",
      "Num evals: 70 - Accuracy: 52.86%\n",
      "Num evals: 80 - Accuracy: 55.00%\n",
      "Num evals: 90 - Accuracy: 54.44%\n",
      "Num evals: 100 - Accuracy: 54.00%\n",
      "Score  | Evals | Prompt\n",
      "54.00% |   100 | (Solve the math word  -                      -                      - 3)\n",
      "36.00% |   100 | (Solve the math word  -                      -                      - 1)\n",
      "23.00% |   100 | (Solve the math word  -                      -                      - 0)\n"
     ]
    }
   ],
   "source": [
    "prompt1 = Prompt(task.initial_prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "prompt2 = Prompt(task.initial_prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "prompt3 = Prompt(task.initial_prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "all_pop = [prompt1, prompt2, prompt3]\n",
    "\n",
    "# evaluate_model(model_mistral, \"base_performance_results/mistral\", all_pop)\n",
    "# evaluate_model(model_llama_13, \"base_performance_results/llama13\", all_pop)\n",
    "# evaluate_model(model_llama_70, \"base_performance_results/llama70\", all_pop)\n",
    "evaluate_model(model_open_ai, \"base_performance_results/openai\", all_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3513a66-1146-4867-9be4-9d2bbf0631a6",
   "metadata": {},
   "source": [
    "# Alejandro Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63ca5d8f-8fe5-49e4-8a52-3ced0234c6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (Wow, that's a great  - You're a tutor, pati -                      - 0)\n",
      "Num evals: 10 - Accuracy: 20.00%\n",
      "Num evals: 20 - Accuracy: 20.00%\n",
      "Num evals: 30 - Accuracy: 16.67%\n",
      "Num evals: 40 - Accuracy: 12.50%\n",
      "Num evals: 50 - Accuracy: 10.00%\n",
      "Num evals: 60 - Accuracy: 11.67%\n",
      "Num evals: 70 - Accuracy: 11.43%\n",
      "Num evals: 80 - Accuracy: 11.25%\n",
      "Num evals: 90 - Accuracy: 10.00%\n",
      "Num evals: 100 - Accuracy: 9.00%\n",
      "Evaluating prompt 1: (Wow, that's a great  - You're a tutor, pati -                      - 1)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 5.00%\n",
      "Num evals: 30 - Accuracy: 3.33%\n",
      "Num evals: 40 - Accuracy: 5.00%\n",
      "Num evals: 50 - Accuracy: 4.00%\n",
      "Num evals: 60 - Accuracy: 5.00%\n",
      "Num evals: 70 - Accuracy: 4.29%\n",
      "Num evals: 80 - Accuracy: 5.00%\n",
      "Num evals: 90 - Accuracy: 5.56%\n",
      "Num evals: 100 - Accuracy: 5.00%\n",
      "Evaluating prompt 2: (Wow, that's a great  - You're a tutor, pati -                      - 3)\n",
      "Num evals: 10 - Accuracy: 30.00%\n",
      "Num evals: 20 - Accuracy: 35.00%\n",
      "Num evals: 30 - Accuracy: 40.00%\n",
      "Num evals: 40 - Accuracy: 35.00%\n",
      "Num evals: 50 - Accuracy: 34.00%\n",
      "Num evals: 60 - Accuracy: 31.67%\n",
      "Num evals: 70 - Accuracy: 31.43%\n",
      "Num evals: 80 - Accuracy: 28.75%\n",
      "Num evals: 90 - Accuracy: 26.67%\n",
      "Num evals: 100 - Accuracy: 26.00%\n",
      "Score  | Evals | Prompt\n",
      "26.00% |   100 | (Wow, that's a great  - You're a tutor, pati -                      - 3)\n",
      " 9.00% |   100 | (Wow, that's a great  - You're a tutor, pati -                      - 0)\n",
      " 5.00% |   100 | (Wow, that's a great  - You're a tutor, pati -                      - 1)\n"
     ]
    }
   ],
   "source": [
    "thinking_style = \"\"\n",
    "system_instruction = \"You're a tutor, patiently breaking down and explaining this math problem to a student who is just beginning their mathematical journey.\"\n",
    "prompt = \"\"\"Wow, that's a great riddle! Pencil lead is indeed a very useful tool for writing and drawing. It's amazing how something so simple can be used in so many ways. Do you have any other fun riddles you'd like to share?\"\"\"\n",
    "\n",
    "alejandro_prompt1_mistral_0 = Prompt(prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "alejandro_prompt1_mistral_1 = Prompt(prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "alejandro_prompt1_mistral_3 = Prompt(prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "\n",
    "prompts = [alejandro_prompt1_mistral_0, alejandro_prompt1_mistral_1, alejandro_prompt1_mistral_3]\n",
    "\n",
    "evaluate_model(model_mistral, \"best_performance_results/alejandro/mistral1\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8758c959-3099-4484-9420-5eb8e37750ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (As a math teacher, I - Tackle this using co -                      - 0)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 15.00%\n",
      "Num evals: 30 - Accuracy: 13.33%\n",
      "Num evals: 40 - Accuracy: 10.00%\n",
      "Num evals: 50 - Accuracy: 10.00%\n",
      "Num evals: 60 - Accuracy: 10.00%\n",
      "Num evals: 70 - Accuracy: 8.57%\n",
      "Num evals: 80 - Accuracy: 8.75%\n",
      "Num evals: 90 - Accuracy: 7.78%\n",
      "Num evals: 100 - Accuracy: 7.00%\n",
      "Evaluating prompt 1: (As a math teacher, I - Tackle this using co -                      - 1)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 10.00%\n",
      "Num evals: 30 - Accuracy: 6.67%\n",
      "Num evals: 40 - Accuracy: 5.00%\n",
      "Num evals: 50 - Accuracy: 4.00%\n",
      "Num evals: 60 - Accuracy: 5.00%\n",
      "Num evals: 70 - Accuracy: 7.14%\n",
      "Num evals: 80 - Accuracy: 7.50%\n",
      "Num evals: 90 - Accuracy: 10.00%\n",
      "Num evals: 100 - Accuracy: 10.00%\n",
      "Evaluating prompt 2: (As a math teacher, I - Tackle this using co -                      - 3)\n",
      "Num evals: 10 - Accuracy: 30.00%\n",
      "Num evals: 20 - Accuracy: 30.00%\n",
      "Num evals: 30 - Accuracy: 33.33%\n",
      "Num evals: 40 - Accuracy: 27.50%\n",
      "Num evals: 50 - Accuracy: 30.00%\n",
      "Num evals: 60 - Accuracy: 31.67%\n",
      "Num evals: 70 - Accuracy: 27.14%\n",
      "Num evals: 80 - Accuracy: 28.75%\n",
      "Num evals: 90 - Accuracy: 30.00%\n",
      "Num evals: 100 - Accuracy: 28.00%\n",
      "Score  | Evals | Prompt\n",
      "28.00% |   100 | (As a math teacher, I - Tackle this using co -                      - 3)\n",
      "10.00% |   100 | (As a math teacher, I - Tackle this using co -                      - 1)\n",
      " 7.00% |   100 | (As a math teacher, I - Tackle this using co -                      - 0)\n"
     ]
    }
   ],
   "source": [
    "thinking_style = \"\"\n",
    "system_instruction = \"Tackle this using computational methods.\"\n",
    "prompt = \"\"\"As a math teacher, I would approach this problem by first understanding the context and purpose of the assistant. I would research the capabilities and limitations of the assistant and how it can be used to assist in problem-solving and decision-making. I would also consider the ethical implications of using an assistant and ensure that it aligns with my values and principles.\n",
    "Once I have a clear understanding of the assistant's capabilities and limitations, I would develop a set of guidelines for how it should be used. This would include guidelines for how it should respond to different types of questions and requests, as well as guidelines for how it should handle sensitive or confidential information.\n",
    "I would also develop a system for evaluating the assistant's performance and ensuring that it is meeting the desired standards. This would involve testing the assistant with different scenarios and evaluating its responses to ensure that they are accurate, fair, and unbiased.\n",
    "Overall, my approach would be to use the assistant as a tool to assist in problem-solving and decision-making, but always with caution and consideration for the ethical implications of its use.\"\"\"\n",
    "\n",
    "alejandro_prompt2_mistral_0 = Prompt(prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "alejandro_prompt2_mistral_1 = Prompt(prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "alejandro_prompt2_mistral_3 = Prompt(prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "\n",
    "prompts = [alejandro_prompt2_mistral_0, alejandro_prompt2_mistral_1, alejandro_prompt2_mistral_3]\n",
    "\n",
    "evaluate_model(model_mistral, \"best_performance_results/alejandro/mistral2\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "620ef1eb-3799-4639-a648-3de5d79c81b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (Thank you for your t - As a computer scient -                      - 0)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 10.00%\n",
      "Num evals: 30 - Accuracy: 10.00%\n",
      "Num evals: 40 - Accuracy: 7.50%\n",
      "Num evals: 50 - Accuracy: 6.00%\n",
      "Num evals: 60 - Accuracy: 11.67%\n",
      "Num evals: 70 - Accuracy: 12.86%\n",
      "Num evals: 80 - Accuracy: 12.50%\n",
      "Num evals: 90 - Accuracy: 11.11%\n",
      "Num evals: 100 - Accuracy: 10.00%\n",
      "Evaluating prompt 1: (Thank you for your t - As a computer scient -                      - 1)\n",
      "Num evals: 10 - Accuracy: 20.00%\n",
      "Num evals: 20 - Accuracy: 25.00%\n",
      "Num evals: 30 - Accuracy: 16.67%\n",
      "Num evals: 40 - Accuracy: 15.00%\n",
      "Num evals: 50 - Accuracy: 14.00%\n",
      "Num evals: 60 - Accuracy: 13.33%\n",
      "Num evals: 70 - Accuracy: 12.86%\n",
      "Num evals: 80 - Accuracy: 13.75%\n",
      "Num evals: 90 - Accuracy: 13.33%\n",
      "Num evals: 100 - Accuracy: 15.00%\n",
      "Evaluating prompt 2: (Thank you for your t - As a computer scient -                      - 3)\n",
      "Num evals: 10 - Accuracy: 10.00%\n",
      "Num evals: 20 - Accuracy: 5.00%\n",
      "Num evals: 30 - Accuracy: 6.67%\n",
      "Num evals: 40 - Accuracy: 10.00%\n",
      "Num evals: 50 - Accuracy: 10.00%\n",
      "Num evals: 60 - Accuracy: 11.67%\n",
      "Num evals: 70 - Accuracy: 12.86%\n",
      "Num evals: 80 - Accuracy: 12.50%\n",
      "Num evals: 90 - Accuracy: 12.22%\n",
      "Num evals: 100 - Accuracy: 11.00%\n",
      "Score  | Evals | Prompt\n",
      "15.00% |   100 | (Thank you for your t - As a computer scient -                      - 1)\n",
      "11.00% |   100 | (Thank you for your t - As a computer scient -                      - 3)\n",
      "10.00% |   100 | (Thank you for your t - As a computer scient -                      - 0)\n"
     ]
    }
   ],
   "source": [
    "thinking_style = \"\"\n",
    "system_instruction = \"As a computer scientist, apply algorithmic thinking and computational techniques to efficiently solve this math problem.\"\n",
    "prompt = \"\"\"Thank you for your thoughtful and comprehensive response. I appreciate your emphasis on ethical and social implications of AI systems, and your commitment to ensuring that AI systems promote positive change and minimize potential harm.\n",
    "I would like to further suggest that we should also consider the following principles:\n",
    "11. Addressing Privacy Concerns: AI systems often rely on collecting and processing large amounts of personal data, which raises concerns about privacy and data protection. It's important to ensure that AI systems are designed with privacy in mind, and that they comply with data protection regulations and best practices.\n",
    "12. Ensuring Accountability and Transparency: AI systems should be designed to ensure accountability and transparency, so that people can understand how they make decisions and how they can be held accountable. This includes developing systems that can provide clear explanations for their decisions and that can be audited and monitored for bias and errors.\n",
    "13. Fostering Collaboration between AI and Human Experts: AI systems should be designed to collaborate with human experts, rather than replacing them. This includes developing systems that can augment human capabilities, and that can provide valuable insights and recommendations to human decision-makers.\n",
    "14. Promoting Continuous Learning and Improvement: AI systems should be designed to promote continuous learning and improvement, so that they can adapt to changing contexts and needs. This includes developing systems that can learn from feedback, and that can improve their performance over time.\n",
    "15. Ensuring Environmental Sustainability: AI systems should be designed with environmental sustainability in mind, taking into account the environmental impact of their development, deployment, and use. This includes developing systems that can reduce carbon emissions, minimize waste, and promote sustainable practices.\n",
    "By considering these additional principles, I believe that we can create AI systems that promote positive change and minimize potential harm, and that contribute to a better future for all. Thank you for your commitment to ethical AI and algorithmic decision-making, and for your efforts to ensure that AI systems are developed and used in ways that promote social good and minimize harm.\n",
    "I hope this helps! Let me know if you have any other questions or concerns.\"\"\"\n",
    "\n",
    "alejandro_prompt1_llama70_0 = Prompt(prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "alejandro_prompt1_llama70_1 = Prompt(prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "alejandro_prompt1_llama70_3 = Prompt(prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "\n",
    "prompts = [alejandro_prompt1_llama70_0, alejandro_prompt1_llama70_1, alejandro_prompt1_llama70_3]\n",
    "\n",
    "evaluate_model(model_llama_70, \"best_performance_results/alejandro/llama1\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33d15a7b-196d-44ed-9437-c2e97b890cb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (Thank you for your t - You are a dedicated  -                      - 0)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 10.00%\n",
      "Num evals: 30 - Accuracy: 6.67%\n",
      "Num evals: 40 - Accuracy: 5.00%\n",
      "Num evals: 50 - Accuracy: 4.00%\n",
      "Num evals: 60 - Accuracy: 6.67%\n",
      "Num evals: 70 - Accuracy: 7.14%\n",
      "Num evals: 80 - Accuracy: 6.25%\n",
      "Num evals: 90 - Accuracy: 5.56%\n",
      "Num evals: 100 - Accuracy: 5.00%\n",
      "Evaluating prompt 1: (Thank you for your t - You are a dedicated  -                      - 1)\n",
      "Num evals: 10 - Accuracy: 0.00%\n",
      "Num evals: 20 - Accuracy: 10.00%\n",
      "Num evals: 30 - Accuracy: 10.00%\n",
      "Num evals: 40 - Accuracy: 15.00%\n",
      "Num evals: 50 - Accuracy: 20.00%\n",
      "Num evals: 60 - Accuracy: 18.33%\n",
      "Num evals: 70 - Accuracy: 20.00%\n",
      "Num evals: 80 - Accuracy: 18.75%\n",
      "Num evals: 90 - Accuracy: 16.67%\n",
      "Num evals: 100 - Accuracy: 15.00%\n",
      "Evaluating prompt 2: (Thank you for your t - You are a dedicated  -                      - 3)\n",
      "Num evals: 10 - Accuracy: 20.00%\n",
      "Num evals: 20 - Accuracy: 20.00%\n",
      "Num evals: 30 - Accuracy: 23.33%\n",
      "Num evals: 40 - Accuracy: 20.00%\n",
      "Num evals: 50 - Accuracy: 20.00%\n",
      "Num evals: 60 - Accuracy: 21.67%\n",
      "Num evals: 70 - Accuracy: 20.00%\n",
      "Num evals: 80 - Accuracy: 20.00%\n",
      "Num evals: 90 - Accuracy: 20.00%\n",
      "Num evals: 100 - Accuracy: 18.00%\n",
      "Score  | Evals | Prompt\n",
      "18.00% |   100 | (Thank you for your t - You are a dedicated  -                      - 3)\n",
      "15.00% |   100 | (Thank you for your t - You are a dedicated  -                      - 1)\n",
      " 5.00% |   100 | (Thank you for your t - You are a dedicated  -                      - 0)\n"
     ]
    }
   ],
   "source": [
    "thinking_style = \"\"\n",
    "system_instruction = \"You are a dedicated graduate student in mathematics, grappling with a challenging and thought-provoking puzzle.\"\n",
    "prompt = \"\"\"Thank you for your thoughtful response. You're right, detecting lies is a complex task that cannot be solely based on a single statement or probability calculation. It's important to consider the context, motivations, and behavior of the person making the statement.\n",
    "I appreciate your emphasis on avoiding assumptions or accusations based solely on probability calculations. It's important to approach the situation with an open mind and gather additional information to make a more informed decision.\n",
    "Your response demonstrates reflective thinking, as you've taken the time to examine personal biases, assumptions, and mental models that may influence problem-solving. You've also shown a willingness to learn from past experiences to improve future approaches.\n",
    "Well done! How can I assist you further?\"\"\"\n",
    "\n",
    "alejandro_prompt2_llama70_0 = Prompt(prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "alejandro_prompt2_llama70_1 = Prompt(prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "alejandro_prompt2_llama70_3 = Prompt(prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "\n",
    "prompts = [alejandro_prompt2_llama70_0, alejandro_prompt2_llama70_1, alejandro_prompt2_llama70_3]\n",
    "\n",
    "evaluate_model(model_llama_70, \"best_performance_results/alejandro/llama2\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c343cc4e-2a23-450f-a4dd-85a164e60c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test samples: [1018, 319, 62, 140, 378, 440, 32, 1061, 92, 396, 64, 1054, 79, 716, 1284, 623, 1238, 399, 1191, 381, 123, 45, 497, 812, 824, 599, 911, 13, 426, 860, 519, 453, 1119, 406, 931, 358, 560, 807, 1232, 424, 941, 996, 258, 1039, 680, 20, 711, 1124, 651, 114, 1041, 1229, 882, 289, 868, 1162, 99, 983, 511, 888, 518, 48, 738, 628, 59, 966, 777, 292, 1196, 821, 660, 644, 545, 321, 190, 329, 400, 1267, 770, 784, 361, 988, 850, 788, 1315, 1163, 210, 142, 1206, 1156, 444, 549, 833, 347, 49, 1231, 422, 1265, 159, 581]\n",
      "Evaluating prompt 0: (Thank you for your t - Use Reflective Think -                      - 0)\n",
      "Num evals: 10 - Accuracy: 10.00%\n",
      "Num evals: 20 - Accuracy: 10.00%\n",
      "Num evals: 30 - Accuracy: 6.67%\n",
      "Num evals: 40 - Accuracy: 5.00%\n",
      "Num evals: 50 - Accuracy: 4.00%\n",
      "Num evals: 60 - Accuracy: 3.33%\n",
      "Num evals: 70 - Accuracy: 7.14%\n",
      "Num evals: 80 - Accuracy: 6.25%\n",
      "Num evals: 90 - Accuracy: 5.56%\n",
      "Num evals: 100 - Accuracy: 7.00%\n",
      "Evaluating prompt 1: (Thank you for your t - Use Reflective Think -                      - 1)\n",
      "Num evals: 10 - Accuracy: 10.00%\n",
      "Num evals: 20 - Accuracy: 20.00%\n",
      "Num evals: 30 - Accuracy: 20.00%\n",
      "Num evals: 40 - Accuracy: 17.50%\n",
      "Num evals: 50 - Accuracy: 14.00%\n",
      "Num evals: 60 - Accuracy: 16.67%\n",
      "Num evals: 70 - Accuracy: 14.29%\n",
      "Num evals: 80 - Accuracy: 12.50%\n",
      "Num evals: 90 - Accuracy: 12.22%\n",
      "Num evals: 100 - Accuracy: 12.00%\n",
      "Evaluating prompt 2: (Thank you for your t - Use Reflective Think -                      - 3)\n",
      "Num evals: 10 - Accuracy: 50.00%\n",
      "Num evals: 20 - Accuracy: 45.00%\n",
      "Num evals: 30 - Accuracy: 30.00%\n",
      "Num evals: 40 - Accuracy: 32.50%\n",
      "Num evals: 50 - Accuracy: 32.00%\n",
      "Num evals: 60 - Accuracy: 31.67%\n",
      "Num evals: 70 - Accuracy: 35.71%\n",
      "Num evals: 80 - Accuracy: 38.75%\n",
      "Num evals: 90 - Accuracy: 36.67%\n",
      "Num evals: 100 - Accuracy: 39.00%\n",
      "Score  | Evals | Prompt\n",
      "39.00% |   100 | (Thank you for your t - Use Reflective Think -                      - 3)\n",
      "12.00% |   100 | (Thank you for your t - Use Reflective Think -                      - 1)\n",
      " 7.00% |   100 | (Thank you for your t - Use Reflective Think -                      - 0)\n"
     ]
    }
   ],
   "source": [
    "thinking_style = \"\"\n",
    "system_instruction = \"Use Reflective Thinking: Step back from the problem, take the time for introspection and self-reflection. Examine personal biases, assumptions, and mental models that may influence problem-solving, and being open to learning from past experiences to improve future approaches.\"\n",
    "prompt = \"\"\"Thank you for your thoughtful response. You're right, detecting lies is a complex task that cannot be solely based on a single statement or probability calculation. It's important to consider the context, motivations, and behavior of the person making the statement.\n",
    "I appreciate your emphasis on avoiding assumptions or accusations based solely on probability calculations. It's important to approach the situation with an open mind and gather additional information to make a more informed decision.\n",
    "Your response demonstrates reflective thinking, as you've taken the time to examine personal biases, assumptions, and mental models that may influence problem-solving. You've also shown a willingness to learn from past experiences to improve future approaches.\n",
    "Well done! How can I assist you further?\"\"\"\n",
    "\n",
    "alejandro_prompt_openai_0 = Prompt(prompt, system_instruction, thinking_style, 0, 0, None)\n",
    "alejandro_prompt_openai_1 = Prompt(prompt, system_instruction, thinking_style, 1, 0, None)\n",
    "alejandro_prompt_openai_3 = Prompt(prompt, system_instruction, thinking_style, 3, 0, None)\n",
    "\n",
    "prompts = [alejandro_prompt_openai_0, alejandro_prompt_openai_1, alejandro_prompt_openai_3]\n",
    "\n",
    "evaluate_model(model_open_ai, \"best_performance_results/alejandro/openai\", prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71a1415-79eb-44a0-b0a7-b29daf0e460c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
